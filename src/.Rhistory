file_name <- paste0(prediction_model, ".R")
path <- paste0("Prediction-Models/", file_name)
source(path)
} else{
file_name <- paste0(prediction_model, ".Rdata")
path <- paste0("Prediction-Models/", file_name)
load(path)
}
source("Evaluation/Evaluation.R")
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
get_new_data = FALSE
# Choose embedding model. The choices are:
# - "word2vec_cbow"
# -
embedding_model = "word2vec_cbow"
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = FALSE
# Choose prediction model. The choices are:
# - "logistic_regression"
prediction_model = "logistic_regression"
# If you want to run the prediction file to get new predictions this is TRUE.
# If you have the predictions saved in an Rdata file then this is FALSE.
get_new_predictions = TRUE
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
fread("../data/cleaned_data.csv")
}
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0(embedding_model, ".Rdata")
path <- paste0("Embedding-Models/", file_name)
load(path)
}
file_name <- paste0("vectorized_", embedding_model, ".csv")
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/", file_name)
load(path)
}
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = TRUE
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/", file_name)
load(path)
}
get_new_data = FALSE
# Choose embedding model. The choices are:
# - "word2vec_cbow"
# -
embedding_model = "word2vec_cbow"
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = TRUE
# Choose prediction model. The choices are:
# - "logistic_regression"
prediction_model = "logistic_regression"
# If you want to run the prediction file to get new predictions this is TRUE.
# If you have the predictions saved in an Rdata file then this is FALSE.
get_new_predictions = TRUE
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
fread("../data/cleaned_data.csv")
}
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/cleaned_data.csv")
}
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/", file_name)
load(path)
}
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/", file_name)
load(path)
}
start_time <- Sys.time()
set.seed(100)
model <- word2vec(x = df$Review_Tokens, type = "cbow", dim = 50, iter = 100)
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/cleaned_data.csv")
}
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/", file_name)
load(path)
}
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/cleaned_data.csv")
}
library(word2vec)
library(data.table)
library(tokenizers)
start_time <- Sys.time()
set.seed(100)
model <- word2vec(x = df$Review_Tokens, type = "cbow", dim = 50, iter = 100)
model <- as.matrix(model)
df <- df[, .(isPositive, Review_Vector)]
View(df)
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/cleaned_data.csv")
}
View(df)
df$Review_Tokens
str(df$Review_Tokens)
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/cleaned_data.csv")
# Splitting the Tokens column into a list of characters
df$Tokens <- strsplit(df$Tokens, "\\|")
}
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Tokens, "\\|")
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Review_Tokens, "\\|")
str(df$Review_Tokens)
View(df)
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/", file_name)
load(path)
}
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/cleaned_data.csv")
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Review_Tokens, "\\|")
}
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/", file_name)
load(path)
}
View(df)
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
get_new_data = TRUE
# Choose embedding model. The choices are:
# - "word2vec_cbow"
# -
embedding_model = "word2vec_cbow"
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = TRUE
# Choose prediction model. The choices are:
# - "logistic_regression"
prediction_model = "logistic_regression"
# If you want to run the prediction file to get new predictions this is TRUE.
# If you have the predictions saved in an Rdata file then this is FALSE.
get_new_predictions = TRUE
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/tokenized_reviews.csv")
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Review_Tokens, "\\|")
}
View(df)
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/", file_name)
load(path)
}
View(df)
if(get_new_predictions){
file_name <- paste0(prediction_model, ".R")
path <- paste0("Prediction-Models/", file_name)
source(path)
} else{
file_name <- paste0(prediction_model, ".Rdata")
path <- paste0("Prediction-Models/", file_name)
load(path)
}
source("Evaluation/Evaluation.R")
df$Tokens
df$Review_Tokens
get_new_data = FALSE
# Choose embedding model. The choices are:
# - "word2vec_cbow"
# -
embedding_model = "word2vec_cbow"
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = FALSE
# Choose prediction model. The choices are:
# - "logistic_regression"
prediction_model = "logistic_regression"
# If you want to run the prediction file to get new predictions this is TRUE.
# If you have the predictions saved in an Rdata file then this is FALSE.
get_new_predictions = TRUE
get_new_data = FALSE
# Choose embedding model. The choices are:
# - "word2vec_cbow"
# -
embedding_model = "word2vec_cbow"
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = FALSE
# Choose prediction model. The choices are:
# - "logistic_regression"
prediction_model = "logistic_regression"
# If you want to run the prediction file to get new predictions this is TRUE.
# If you have the predictions saved in an Rdata file then this is FALSE.
get_new_predictions = TRUE
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/tokenized_reviews.csv")
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Review_Tokens, "\\|")
}
df$Review_Tokens
library(data.table)
library(glove)
install.packages("glove")
library(textEmbed)
install.packages("textEmbed")
library(text2vec)
?glove
??glove
tokens <- strsplit(df$Review, split = " ", fixed = TRUE)
library(data.table)
library(text2vec)
library(tm)
library(tokenizers)
train <- fread("../data/train.csv")
test <- fread("../data/test.csv")
# Change variable names
setnames(train, old = c("V1", "V2", "V3"), new = c("isPositive", "Title", "Review"))
setnames(test, old = c("V1", "V2", "V3"), new = c("isPositive", "Title", "Review"))
# Make positive value 1 and negative value 0
train$isPositive <- train$isPositive - 1
test$isPositive <- test$isPositive - 1
# Transform the isPositive variable to a logical variable
train$isPositive <- as.logical(train$isPositive)
test$isPositive <- as.logical(test$isPositive)
# Merge train and test data.
df <- rbind(train, test)
# Temporary dataset to test code on
df <- head(df, 1000)
start_time <- Sys.time()
# Remove stop words, punctuation, whitespace, numbers and make everything lower case
df$Review <- removePunctuation(df$Review)
df$Review <- removeNumbers(df$Review)
df$Review <- tolower(df$Review)
df$Review <- removeWords(df$Review, stopwords('en'))
df$Review <- stripWhitespace(df$Review)
# Remove leading whitespace
df$Review <- gsub("^\\s+", "", df$Review)
tokens <- strsplit(df$Review, split = " ", fixed = T)
# Create vocabulary to remove the words that appear less than 5 times in the vocabulary
vocabulary <- create_vocabulary(itoken(tokens), ngram= c(1,1))
vocabulary <- prune_vocabulary(vocabulary, term_count_min = 5)
# Create a function to filter words based on vocabulary
filter_review <- function(review, vocab) {
words <- unlist(strsplit(review, " "))  # Split review into words
filtered_words <- words[words %in% vocab]  # Keep only words present in vocabulary
filtered_review <- paste(filtered_words, collapse = " ")  # Reconstruct the review
return(filtered_review)
}
# Remove words from the Review column that are not in the vocabulary
df$Review <- sapply(df$Review, filter_review, vocab = vocabulary$term)
# Create a column called Review_Tokens
df$Review_Tokens <- sapply(df$Review, function(review) tokenize_words(review))
tokens <- strsplit(df$Review, split = " ", fixed = TRUE)
df <- df[, .(isPositive, Review_Tokens)]
end_time <- Sys.time()
# Total execution time
total_execution_time <- as.numeric(difftime(end_time, start_time, units = "secs"))
cat("Total execution time:", total_execution_time, "seconds \n")
cat("Estimated execution time for full dataset is", total_execution_time*(4000000/nrow(df)), "seconds. Which is", total_execution_time*(4000000/nrow(df))/3600, "hours \n")
# Write df to a CSV file
fwrite(df, "../data/tokenized_reviews.csv")
tokens
??itoken
?itoken
iter <- itoken(df$Review_Tokens)
vectorizer <- vocab_vectorizer(vocabulary)
tcm <- create_tcm(iter, vectorizer)
View(tcm)
fit.glove <- glove(tcm = tcm,
word_vectors_size = 50,
x_max = 10, learning_rate = 0.2,
num_iters = 15)
?glove
??glove
fit.glove <- text2vec::glove(tcm = tcm,
word_vectors_size = 50,
x_max = 10, learning_rate = 0.2,
num_iters = 15)
??GlobalVectors
fit.glove <- GloVe(tcm = tcm,
word_vectors_size = 50,
x_max = 10, learning_rate = 0.2,
num_iters = 15)
??GlobalVectors
library(rspare)
library(rsparse)
fit.glove <- GloVe(tcm = tcm,
word_vectors_size = 50,
x_max = 10, learning_rate = 0.2,
num_iters = 15)
fit.glove <- GloVe$new(tcm = tcm,
word_vectors_size = 50,
x_max = 10, learning_rate = 0.2,
num_iters = 15)
fit.glove <- GloVe$fit_transform(
x = tcm,
n_iter = 15)
fit.glove <- GloVe$new(
x = tcm,
n_iter = 15)
?Glove$new
glove_model <- GloVe$new(word_vectors_dim = word_vectors_dim,
window_size = window_size,
alpha = 0.75,  # Learning rate
max_iter = iterations,
tol = 1e-4)
word_vectors_dim <- 100  # Size of the embedding vector
window_size <- 10        # Context window size
iterations <- 10         # Number of iterations
glove_model <- GloVe$new(word_vectors_dim = word_vectors_dim,
window_size = window_size,
alpha = 0.75,  # Learning rate
max_iter = iterations,
tol = 1e-4)
glove_model <- GloVe$new(alpha = 0.75)  # Learning rate
glove_model <- GloVe$new(rank = 4,
alpha = 0.75)  # Learning rate
# Train GloVe embeddings
glove_model <- GloVe$new(rank = word_vectors_dim,
x_max = 100,
x_min = 1e-8,
learning_rate = learning_rate,
max_iter = iterations,
verbose = TRUE)
# Train GloVe embeddings
glove_model <- GloVe$new(rank = word_vectors_dim,
x_max = 100,
learning_rate = learning_rate)
# Train GloVe embeddings
glove_model <- GloVe$new(rank = word_vectors_dim,
x_max = 100,
learning_rate = 0.2)
glove_model$fit_transform(tcm)
# Extract trained word embeddings
word_embeddings <- glove_model$components
View(word_embeddings)
source("Review-Vectorization/Review_vectorization.R")
View(df)
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
get_new_data = FALSE
# Choose embedding model. The choices are:
# - "word2vec_cbow"
# -
embedding_model = "word2vec_cbow"
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = FALSE
# Choose prediction model. The choices are:
# - "logistic_regression"
prediction_model = "logistic_regression"
# If you want to run the prediction file to get new predictions this is TRUE.
# If you have the predictions saved in an Rdata file then this is FALSE.
get_new_predictions = TRUE
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/tokenized_reviews.csv")
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Review_Tokens, "\\|")
}
library(data.table)
library(text2vec)
library(rsparse)
iter <- itoken(df$Review_Tokens)
vectorizer <- vocab_vectorizer(vocabulary)
tcm <- create_tcm(iter, vectorizer)
library(word2vec)
library(data.table)
library(tokenizers)
start_time <- Sys.time()
set.seed(100)
model <- word2vec(x = df$Review_Tokens, type = "cbow", dim = 50, iter = 50)
source("Review-Vectorization/Review_vectorization.R")
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/tokenized_reviews.csv")
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Review_Tokens, "\\|")
}
library(word2vec)
library(data.table)
library(tokenizers)
start_time <- Sys.time()
set.seed(100)
model <- word2vec(x = df$Review_Tokens, type = "cbow", dim = 50, iter = 50)
source("Review-Vectorization/Review_vectorization.R")
get_new_data = FALSE
# Choose embedding model. The choices are:
# - "word2vec_cbow"
# -
embedding_model = "word2vec_cbow"
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = FALSE
# Choose prediction model. The choices are:
# - "logistic_regression"
prediction_model = "logistic_regression"
# If you want to run the prediction file to get new predictions this is TRUE.
# If you have the predictions saved in an Rdata file then this is FALSE.
get_new_predictions = TRUE
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/tokenized_reviews.csv")
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Review_Tokens, "\\|")
}
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/Embedded-Reviews/", file_name)
load(path)
}
get_new_data = FALSE
# Choose embedding model. The choices are:
# - "word2vec_cbow"
# -
embedding_model = "word2vec_cbow"
# If you want to run the embeddings file to get new embeddings this is TRUE.
# If you have the model saved in a Rdata file then this is FALSE.
get_new_embeddings = TRUE
# Choose prediction model. The choices are:
# - "logistic_regression"
prediction_model = "logistic_regression"
# If you want to run the prediction file to get new predictions this is TRUE.
# If you have the predictions saved in an Rdata file then this is FALSE.
get_new_predictions = TRUE
if(get_new_data){
source("Preprocessing/Cleaning.R")
} else{
df <- fread("../data/tokenized_reviews.csv")
# Splitting the Tokens column into a list of characters
df$Review_Tokens <- strsplit(df$Review_Tokens, "\\|")
}
if(get_new_embeddings){
file_name <- paste0(embedding_model, ".R")
path <- paste0("Embedding-Models/", file_name)
source(path)
} else{
file_name <- paste0("vectorized_", embedding_model, ".csv")
path <- paste0("../data/Embedded-Reviews/", file_name)
load(path)
}
View(model)
